<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>uncertain augur</title>
    <link href="https://uncertain-augur.github.io/atom.xml" rel="self" />
    <link href="https://uncertain-augur.github.io" />
    <id>https://uncertain-augur.github.io/atom.xml</id>
    <author>
        <name></name>
        <email></email>
    </author>
    <updated>2020-06-10T00:00:00Z</updated>
    <entry>
    <title>Actually using the OODA loop concept</title>
    <link href="https://uncertain-augur.github.io/posts/OODA/index.html" />
    <id>https://uncertain-augur.github.io/posts/OODA/index.html</id>
    <published>2020-06-10T00:00:00Z</published>
    <updated>2020-06-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!---
Thinking about OODA as a descriptive model. 

- Everyone knows Boyd's OODA.
- How I think of it: Descriptive, multi-scale model
- Not something you explicitly do.
- Used to analyze the key points of an adaptive system.
- Happening at multiple levels at the same time- reflexes, thinking, longer-term
  planning.
- Doesn't give you truth, just a framework.
--->
<p>If you’ve spent any time around modern American military thought, or strategy more broadly, you’ve almost certainly come across John Boyd’s observe-orient-decide-act (OODA) loop. It’s ubiquitous in tactical circles, and I think has an often under-appreciated role in the intellectual heritage of the lean startup community.</p>
<p>There are a lot of good articles on Boyd’s life and ideas floating around already, so I simply wanted to reflect a little bit on how I personally think about the OODA idea, and mental models more broadly.</p>
<p><img src="../../images/ooda.png" /> <span class="marginnote"> Obligatory: Boyd’s full OODA loop. </span></p>
<p>I was prompted into this by a couple of articles that approached the topic in a way very different from how I do. The first was a tactics instructor, talking about the OODA loop in the context of gunfighting and situational awareness. He described the OODA loop as a tool, a thing that one “should” do- to survive a gunfight, one should observe, understand what you’re observing, come to a decision, execute, and repeat. The second was a popular article, using OODA as a way to talk about decision-making more generally (the author had a USAF background). This was even more explicit about separating the phases of the OODA loop, highlighting the deliberate separation of the phases as one of the loop’s key “lessons”.</p>
<p>Separating information-gathering and decision-making can often be useful, and I have no doubt that the shooting instructor, a combat veteran, knows his stuff when it comes to gunfighting. Yet I can’t shake the feeling that talking about OODA as something one “should” do misses something fundamental.</p>
<p>In its simplest form, the OODA loop is a descriptive model of an open system responding to its environment in a feedback loop. It can be applied, with varying degrees of usefulness, to something as complex as a nation-state or as simple as an electronic control circuit. In each case, we have information flowing into a sensor or sensors. That information is filtered and processed to extract a signal from the information. That signal is evaluated, a selection from a possible set of actions is made. This decision flows outward, to systems or actuators that will translate it to an effect on the world.</p>
<p>For a system in isolation, or a system coupled to a large, complex-enough world that doesn’t take much interest in it<span><label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle"/><span class="sidenote">A sort of mean-field approximation. If you’re a sole trader with a $500 Robinhood account, it’s fairly reasonable to treat the market an external entity, unresponsive to your actions. If you’re running the investment banking arm of a major Wall Street bank, it is not.<br />
<br />
</span></span>, one loop might be enough to describe the situation. If you have multiple agents that are explicitly concentrating on and responding to one another, you might need two or more loops to accurately describe the system, and the interesting dynamics emerge from the interplay between them.</p>
<p>In either case, the loop alone isn’t enough to tell you what to do, or even what will happen. Instead, it’s almost an attention management tool, letting you understand where to direct your focus in order to break up a problem. In general, this is how I try to think about mental models, and actually use them in practice. Like Gigerenzer’s heuristics, mental models let us filter down the complexity of the world into something we can manage. Unlike heuristics, which give us more or less prescriptive actions, mental models usually give us dynamics, a set of rules for predicting how our simplified picture of the world will play out. The conclusions depend on what you want, and how that model interacts with others.</p>
<p>This is why I’m personally not a fan of discussions of the OODA loop that focus on it as something decision makers should do, or as something that “tells” us the secret to victory in war (or business, or romance, or what have you) is to go faster. In the same way that a Newtonian model of mechanics lets us understand a machine by focusing on a particular description of it, OODA is a starting point for analysis<span><label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle"/><span class="sidenote">More polemically, saying an agent “should” use an OODA process is like saying a machine should involve forces- not really an insight, just a description. A human not undergoing some form of OODA process is called a corpse.<br />
<br />
</span></span>. The loop doesn’t tell us to go faster. Boyd does, as part of his greater theory, based on the analysis of the type of situations he tends to focus on: high-uncertainty, dynamic, bounded-rationality situations, where our understanding of the situation is always imperfect, and rapidly going out of date<span><label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle"/><span class="sidenote">In these cases, he’s usually right, mind.<br />
<br />
</span></span>.</p>
<p>So, what’s the takeaway? Next time you have a problem that involves finding your way through uncertainty or conflict, how do you actually “use” the OODA loop?</p>
<p>Well, you use it to think. If you have a chance, do it on paper. Sketch a loop like the one above; one for yourself, and one for your adversary, if you have one. Then start to wrap meat around the abstract skeleton. What are you observing? The movements of an opponent in the ring? Medical vital signs? Customer emails? When you orient, what does that actually mean? What do you pay attention to or think about? How do you decide what to do, and how are those carried out? Likewise, for your opponent: you might not know everything, but you probably know more than you think: how do they learn about what you do? What do they pay attention to? How do you think they think? How do they think you think? How do they think you think they think…?</p>
<pre><code>He registered and got the key and hobbled up the steps and
down the hall to his room and went in and locked the door and
lay on the bed with the shotgun across his chest staring at the
ceiling. He could think of no reason for the transponder sending
unit to be in the hotel. He ruled out Moss because he thought
Moss was almost certainly dead. That left the police. Or some
agent of the Matacumbe Petroleum Group. Who must think that
he thought that they thought that he thought they were very
dumb. He thought about that.
- No Country For Old Men</code></pre>
<p>When you have your model, play with it. What do you see, from a point of comfortable, Olympian reflection that you tend to miss when you’re busy actually doing things? Does your basic rhythm truly move you toward where you want to go? If you go faster, do you move closer to your goal, or just increase your risk? If you have an adversary, can you go than them? If not, can you slow them down, or bias them enough that their speed only helps them divert off course faster? This is the hard part, the creative part, the part that makes mental models tools for thinking, and not just cookie-cutter maxims. If nothing useful emerges, put it aside, try another model for the situation, and return a little later with a fresh perspective; when you’re trying to understand the world, it pays to be a Tetlockian hedgehog.</p>
<p>And, finally, if all else fails? If you don’t have the time or energy for that kind of analysis, if things are too murky, if there’s too much going on you don’t understand? Then probably, yeah, just go faster. In an unclear, changing situation, the heuristic is to choose whatever course of action lets you learn fast and adapt to that new information quickly. As previously discussed, I think that you want to be pairing conscious, detailed System 2 mental models with intuitive System 1 heuristics, and this is a perfect example. When you’ve done that, however, and you have time to take a breather, stop, take the information you’ve gained, and think more deeply about what’s really going on. The OODA loop has a lot more to offer than raw speed.</p>]]></summary>
</entry>
<entry>
    <title>Baseball, Fighter Pilots, and Trauma Medicine: Good Decisions with Heuristics</title>
    <link href="https://uncertain-augur.github.io/posts/fftrees/index.html" />
    <id>https://uncertain-augur.github.io/posts/fftrees/index.html</id>
    <published>2020-06-06T00:00:00Z</published>
    <updated>2020-06-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p><img src="../../images/spitfire.jpg" /></p>
<p>There’s a fascinating wing of decision science called ecological rationality. This work studies the problem of how it is that people are able to make decisions in the real world, under pressure, and in the face of what from an academic standpoint look like overwhelming information processing requirements. We are able to do this by using heuristics, decision rules that aggressively filter available information to focus on a few key signals.</p>
<p>The 101 example of this is the gaze heuristic, which emerges when someone (or something) is trying to solve the problem of intercepting a moving object, such as a catcher trying to catch an incoming flying ball. A computer program designed to solve this problem and plan the runner’s path might model the physics of the system, compute a trajectory for the ball, solve for the optimal impact point, and then move to that point. If it were an online system, it might update its estimates of the parameters of the ball in-flight, checking the ball’s movement against its internal model, and refining its estimate at each step.</p>
<p>It’s clear that no human being can replicate this method. What is interesting is that we don’t appear to even approximate it. Trying to divine the internal reasoning processes of human beings is a challenging and finicky science, but we find no evidence in either neurobiology or conversations with expert athletes for a “physics model” type of process. Instead, the solution is simple: fix your eye on the ball, and move so that the angle of your eye doesn’t change. If you do this, your path will coincide with that of the ball<span><label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle"/><span class="sidenote">Of course, nothing in life is this simple. Prior to the throw, the catcher’s brain would be processing an incredible amount of sensory input and associative memory, ranging from the intentions of the thrower to the direction of the wind. While running, the catcher would (hopefully) avoid obstacles, and in the terminal phase a complex set of conscious and trained/unconscious muscle patterns would come in to play. However, the basic point- that the core planning task was accomplished by focusing on a very small subset of the potential information available- holds true.<br />
<br />
</span></span>. This appears over and over again, wherever variations on this problem are found: anywhere from Ultimate Frisbee to the hunting behaviours of predatory animals and bomber-interception strategies employed by RAF pilots during WWII. <img src="../../images/cheetah-hunting.jpg" /> <span class="marginnote"> Figure: A decision professional employing the gaze heuristic at work. </span></p>
<p>The gaze heuristic is an example of what the leading researcher in this field, Gerd Gigerenzer refers to as a one-clever-cue heuristic<span><label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle"/><span class="sidenote">Heuristic Decision Making. Gigerenzer and Gaissmaier, 2011. Annu. Rev. Psychol. 2011.62:451-82.<br />
<br />
</span></span>, focusing on a single piece of crucial information to the exclusion of everything else that might be relevant. This is one of many types of heuristics in the literature, showing how we can handle decision, classification, and resource-allocation problems with restricted amounts of information. Much of this work deals with understanding how human cognitive processes work, and reflects the ongoing academic battle between the ecological rationality school and students of Kahneman and Tversky’s work (somewhat confusingly referred to as the heuristics and biases school) that views heuristics as flaws or deviations from rational decision-making.</p>
<p>The scientific debate is interesting, but for the practically minded, not obviously useful. For that matter, neither is the gaze heuristic, unless your day-to-day work involves gazelle predation or engagements with the Luftwaffe. When we try to extract more general principles, the unifying theme of Gigerenzer’s work is that these heuristics are “ecologically rational”- somewhat tautologically, rational heuristics are ones that tend to work in the environment in which they are employed. As advice goes, “only focus on the information that matters” is only marginally more useful than “try not to lose”. However, I believe that there is, in fact, significant pragmatic value here, and that understanding how we use heuristics naturally can guide us in how we think, decide, and learn.</p>
<p>To think about how this might actually help with our own decision flow, let’s shift domains, and take two examples from a different field that nevertheless requires quick decision-making: emergency medicine.</p>
<p>The first example is a well-studied research case from the ecological rationality literature, where emergency room physicians used a heuristic tool to sort patients into high and low-risk categories for heart attacks. The tool used was slightly more complex than the gaze heuristic: doctors were given three signs to check, in a specific order, with thresholds given for each value to classify as good or bad.. For each cue, one result meant an immediate decision (the rest of the checks were ignored), while patients falling into the other category had the next vital checked, and the process repeated. No information was considered a second time; no looping back. You might recognize this process as a decision tree, albeit a heavily pruned one. This specific structure is referred to as a fast-and-frugal tree, or FFT<span><label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle"/><span class="sidenote">The unfortunate naming overlap with the fast Fourier transform is usually unimportant in psychology, and aggravating in machine learning.<br />
<br />
</span></span>. In an FFT, each piece of information is only considered once, and each decision node has at least one branch that leads to an immediate decision.<br />
<img src="../../images/cardio-fft.png" /> <span class="marginnote"> The fast-and-frugal tree for cardiac risk assessment used in emergency rooms by Green and Mehr, 1997. </span></p>
<p>There are a couple of interesting things to note about this tool. First, it does well: under test conditions, the heuristic was competitive with a logistic-regression model that considered many more variable simultaneously<span><label for="sn-4" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-4" class="margin-toggle"/><span class="sidenote">In fact, it outperformed the model under many circumstances. This appears to be due to a tendency to get less confused by anomalies or outliers in either the training or test data, or more technically, robustness to overfitting. The ability of simple rules to sometimes outperform more complicated models, even when thinking/computation time is not a limiting factor, is an interesting topic for another time- suffice to say that it can both help us understand why, exactly, heuristics work so well in nature, and possibly provide some clues for dealing with complex real-world systems, where any practical amount of computation may still be insufficient.<br />
<br />
</span></span>. What’s more, doctors were much more willing to use it. Not only was it more convenient than a computer program, but it provided an comprehensible logic that the regression model’s inscrutable, black-box judgements lacked.</p>
<p>Second: unlike the gaze heuristic, which emerges naturally in humans and animals, this heuristic was deliberately designed. The cues and threshold values for the branches of the tree were chosen by experts, who had the luxury of time and contemplation not available to the doctor standing at a bedside in the ER. The tree provides a way of compressing that expertise, data, and deliberation down into a format that’s usable and accessible by someone else in the field. Teaching someone to think like a regression model is impossible, getting them to run to a computer to use one in a high-pressure environment is often impractical, but something as simple as the tree above can be committed to memory or a pocket notepad, and kept no more than a second away.</p>
<p><img src="../../images/uk-mountain-first-aid.jpg" /> <span class="marginnote"> UK Mountain Rescue team providing remote first aid. Wilderness emergency medicine provides a rich library of situations where people (who often are not full-time medical professionals) have to make challenging, highly consequential decisions under time pressure, with limited diagnostic tools, few options, and no external decision support. </span></p>
<p>The second example is also from emergency medicine, this time first aid, and will be familiar to many more of you- the ABCDE initial assessment<span><label for="sn-5" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-5" class="margin-toggle"/><span class="sidenote">I’m using the one that I was originally taught here: Airway, breathing, circulation, disability (spinal injury), and environmental exposure. There are a number of variations, as we will discuss.<br />
<br />
</span></span> procedure for CPR and first aid. This is typically taught as a priority list of procedures: check the airway. If obstructed, immediately stop and clear. Otherwise, move on to check for breathing, and so forth. Although this isn’t typically thought of as a heuristic or FFT, I would argue that it meets our definition. First, we aggressively filter information. In the event that a patient is not noticeably breathing, we move immediately to CPR without checking for a pulse, because most of the time, the cost of inaction is much more significant than the rare cases where the patient is not breathing but has a heartbeat. Second, we fit the fast-and-frugal tree structure: we check each cue, sequentially, and if it is unacceptable, we take immediate corrective action. One cue, one exit node.</p>
<p>The interesting point here is not that viewing ABCDE or other first-aid procedures as heuristics immediately makes us better medics, but for the implications for planning and training. The ABCDE assessment is universal for a reason: it works, and it helps people in extremely stressful circumstances act appropriately. I would argue that this, at least in part, is because it provides a frugal decision tree structure that fits smoothly into how we naturally think. We are not, as a rule, good at weighing large numbers of variables simultaneously. We are very good at focusing on specific cues and deciding if we consider them to be good or bad. Having an external structure lets us do this in a way that’s reliable, easily communicated<span><label for="sn-6" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-6" class="margin-toggle"/><span class="sidenote">I speculate, but I imagine that if you took a class of novice first-aiders, and drilled them on the physiology behind the ABC assessment without actually teaching it, they would simply re-invent it after a couple rounds of scenario training. Each medic would understand the importance of airway, checking for major bleeding, and so forth, and develop a list of cues and classifications in order to do this. The difference, of course, is that this would take longer to learn, and consistency/communication between teammates would be much harder.<br />
<br />
</span></span>, and transparent. With an explicit heuristic, it’s possible for teams to both communicate and learn scientifically (such as the recent move, coming from the TCCC community, to move hemorrhage management to before airway) in a way would be much harder if each caregiver were following an internal, less conscious list of rules.</p>
<p>So, we’ve now seen two examples of deliberately designed FFT heuristics: one from the research literature, one widespread tool from first aid that also happens to fit our definition. So, what are the takeaways here?</p>
<p>The first is the core message of the ecological rationality school: heuristics can work. Relatively simple rules, focusing on a small amount of the available information, let us make correct decisions that matter in real world situations, not just when studying toy problems.</p>
<p>The second is that heuristic tools prove easy to adopt and teach. Again, I would argue that this is because they reflect and augment how we already think. In martial arts or other athletics, we use techniques that reflect our natural biomechanics and maximize their potential, rather than trying to force our bodies into movements for which they’re ill-suited. In the same way, heuristics give us a way of structuring decisions that fits our mental biomechanics. The fact that ABC is a convenient acronym is helpful, but that’s not why it’s a useful tool (as many, many excruciating failed acronyms can attest). It’s useful because it takes what we’d do anyway, checking cues and classifying them as good/bad, and infuses it with our collective, conscious knowledge of medicine and biology.</p>
<p>Finally, I think this is something you can use when trying to work on your own thought and decision processes. Recognize that when your rational, System 2 resources are insufficient (either because you’re under time/resource pressure, or because the world is often simply too complex to model and comprehend) you’re going to default to using heuristics. If you do this unconsciously, you run the risk that they don’t reflect your best conscious understanding of the world (a source of “wait, why did I do that?” moments) or worse, are actively irrational, originating from unrepresentative one-off experiences or past traumatic incidents.</p>
<p>Next time you reflect on a decision you had to make under uncertain circumstances, try sketching a tree like the one above, and see how well it describes your thinking. What did you worry about? What cues were you using? Where were the cutoffs, and what different information would have given you pause or changed your mind?</p>
<p>Likewise, when you’re planning, reflecting on a problem, or preparing a training scenario (for yourself, or others) play around with looking at things in terms of cues and cutoffs, rules of thumb and frugal trees. If you ended up having to make a decision, lacking time, lacking information, how would you aim to get things right most of the time? The goal here, to use Kahneman’s terminology, is to bring your System 1 and System 2 into alignment: your conscious, reflective System 2 mind should be aware of what your System 1 mind will do in the moment, and your System 1 should- as much as possible- be equipped with the best of what your conscious mind has worked so hard to learn and understand.</p>]]></summary>
</entry>

</feed>
